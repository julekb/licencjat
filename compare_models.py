import numpy as np
import pandas as pd
import pickle as pkl

from math import exp, log

from sklearn import cross_validation, linear_model
from sklearn.neighbors import KNeighborsRegressor as KNR
from itertools import combinations, product, zip_longest
from sklearn.metrics import mean_squared_error as mse

# loading DataFrame with calculated individual linear models
path = 'pkl_data/'

"""
with open(path+'avg_data.pkl', 'rb') as f:
	avg_data = pkl.load(f)
avg_data = avg_data.sort_values('stimulus')
avg_data = avg_data.reset_index(drop=True)

with open(path+'data_all.pkl', 'rb') as f:
	data_all = pkl.load(f)
for d in data_all:
	d = d.sort_values('stimulus')
	d = d.reset_index(drop=True)
"""

# creating zero model y=x
zero = linear_model.LinearRegression()
zero.intercept_, zero.coef_ = 0, np.array(1)

model_names = ["regr", "regr_ey", "regr_log", "nb1NN", "nb2NN", "nb3NN"]

def fit_model(X, Y):
	#### function for generating linear model for individual ####
	X = [[x] for x in X]
	regr = linear_model.LinearRegression().fit(X, Y)
	regr_ey = linear_model.LinearRegression().fit(np.exp(X), Y)
	regr_log = linear_model.LinearRegression().fit(np.log(X), Y)
	nb1NN = KNR(n_neighbors=1, algorithm='ball_tree').fit(X, Y)
	nb2NN = KNR(n_neighbors=2, algorithm='ball_tree').fit(X, Y)
	nb3NN = KNR(n_neighbors=3, algorithm='ball_tree').fit(X, Y)

	return [regr, regr_ey, regr_log, nb1NN, nb2NN, nb3NN]

def find_models(avg_data, data_all):
	#### function for generating linear models for all agents/participants ####

	participants = len(data_all)
	N = len(data_all[0])

	# creating dataframe; columns include all type of models, their inverse and remained data from cross validation for further computations
	column_names = model_names + ['inv '+name for name in model_names] + ['remain']
	multi = pd.MultiIndex.from_tuples([(i,j) for i in range(participants) for j in list(range(N))])
	df = pd.DataFrame(index=multi, columns=column_names)
	col_len = len(column_names)-1

	X = avg_data['mean']

	# iteration over all agents and fitting models
	for i, agent in enumerate(data_all):
		# cross validation
		kf = cross_validation.LeaveOneOut(N)
		Y = agent['converted']
		for (train_index, test_index) in kf:
			X_train = X[train_index]
			Y_train = Y[train_index]
			models = fit_model(X_train, Y_train)
			models_inv = fit_model(Y_train, X_train)
			df.loc[i,test_index[0]][:col_len] = models+models_inv
			df.loc[i,test_index[0]][col_len] = Y[test_index]
	return df

def save_models_script():
	#### function for saving individual linear models to pickle file ####
	ind_models = find_models()
	with open(path+'ind_models.pkl', 'wb') as f:
		pkl.dump(ind_models, f)

def load_models_script(Return=False):
	#### loading models generated by save_models_script() ####
	with open(path+'ind_models.pkl', 'rb') as f:
		ind_models = pkl.load(f)
	if Return:
		return ind_models
	return

def fight(A_y, B_y, A_model, A_model_inv, B_model, B_model_inv):
	#### function returning answer difference with models ####
	# A_y, B_y - answers agents A and B
	# type is model type (linear, NN)

	d_A = A_y - float(A_model.predict(float(B_model_inv.predict(B_y))))
	d_B = float(B_model.predict(float(A_model_inv.predict(A_y)))) - B_y
	return d_A, d_B

def compare_errors(ind_models, data_all):
	#### comparing communication error with and without individual model ####

	participants = len(data_all)
	N = len(data_all[0])

	column_names = [k+' '+l for l in ['d_A', 'd_B'] for k in model_names]+['no model error']
	multi = pd.MultiIndex.from_tuples([(i,j,k) for i in range(participants) for j in range(i+1,participants) for k in range(N)], names=['agent A', 'agent B', 'iteration'])
	df_err = pd.DataFrame(index=multi, columns=column_names)

	for i in range(participants):
		for j in range(i+1,participants):
			for k in range(N):
				A, B = ind_models.loc[i,k], ind_models.loc[j,k]
				# between agents difference without individual model
				no_mod_err = A['remain'] - B['remain']
				df_err.loc[i,j,k]['no model error'] = no_mod_err
				#  between  difference for agent A and B
				for model in model_names:
					d_A, d_B = fight(A['remain'], B['remain'], A[model], A['inv '+model], B[model], B['inv '+model])
					
					df_err.loc[i,j,k][model+' d_A'] = d_A
					df_err.loc[i,j,k][model+' d_B'] = d_B
					df_err.loc[i,j,k][model+' mse'] = (d_A*d_A + d_B*d_B)/2
					# df_err.loc[i,j,k][model+' diff'] = no_mod_err - (d_A-)

	return df_err

def save_errors_script():
	#### function for saving dataframe with errors ####
	ind= load_models_script(True)
	df_err = compare_errors(ind)
	# with open(path+'df_err.pkl', 'wb') as f:
	# 	pkl.dump(df_err, f)
	return df_err
	

def mse_da_db(df, model_name):
	#### function for counting mse error (d_A^2 + b_B^2)/2 ####
	# df is a file with d_A and d_B data.

	multi = pd.MultiIndex.from_tuples([(i,j,k) for i in range(participants) for j in range(i+1,participants) for k in range(N)], names=['agent A', 'agent B', 'iteration'])
	df_mse = pd.DataFrame(index=multi, columns=[model_name+' mse'])


	for row in df.iterrows():
		index = row[0]
		d_A = row[1][0]
		d_B = row[1][1]
		df_mse.loc(index)[model_name+' mse'] = ( d_A*d_A + d_B*d_B ) / 2
		if (index[2]==0):
			print(index)

	return df_mse



